{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import tnt\n",
    "\n",
    "from nltk.corpus import indian\n",
    "\n",
    "train_data = indian.tagged_sents('hindi.pos')\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['राम', 'ने', 'श्याम', 'को', 'मार', 'डाला']\n"
     ]
    }
   ],
   "source": [
    "data = \"राम ने श्याम को मार डाला\"\n",
    "data = data.replace('।',\"\")\n",
    "    \n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiwn import pyiwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('राम', 'Unk'), ('ने', 'PREP'), ('श्याम', 'Unk'), ('को', 'PREP'), ('मार', 'VFM'), ('डाला', 'VAUX')]\n"
     ]
    }
   ],
   "source": [
    "tagged_words = (tnt_pos_tagger.tag(word_tokenize(data)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwn = pyiwn.IndoWordNet('hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyiwn.pyiwn.IndoWordNet at 0x7f7d26d544e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = word_tokenize(data)\n",
    "f = open('stopwords.txt')\n",
    "stopwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['राम', 'ने', 'श्याम', 'को', 'मार', 'डाला']\n"
     ]
    }
   ],
   "source": [
    "final_words = []\n",
    "for word in tokenized_words:\n",
    "    word = word.replace('।',\"\")\n",
    "    final_words.append(word)\n",
    "\n",
    "        \n",
    "print(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: राम\n",
      "Word: ने\n",
      "Word: श्याम\n",
      "Word: को\n",
      "Word: मार\n",
      "Word: डाल\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "final_words = map(hi_stem,final_words)\n",
    "for word in final_words:\n",
    "    syns = iwn.synsets(word)\n",
    "    \n",
    "    print(\"Word:\", word)\n",
    "    if syns == []:\n",
    "        continue\n",
    "\n",
    "#         syn = syns[0]\n",
    "#         print(syn.lemmas())\n",
    "#         print(\"Gloss:\",syn.gloss())\n",
    "#         print(\"Examples\")\n",
    "#         print(syn.examples())\n",
    "    syn = syns[0]\n",
    "    word_dict[word] = syn.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['राम', 'ने', 'श्याम', 'की', 'हत्या', 'कर', 'दी']\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"राम ने श्याम की हत्या कर दी\"\n",
    "tokenized_words = word_tokenize(new_sentence)\n",
    "tokenized_word = map(hi_stem,tokenized_words)\n",
    "print(tokenized_words)\n",
    "new_wd = {}\n",
    "for word in tokenized_words:\n",
    "    syns = iwn.synsets(word)\n",
    "    if syns == []:\n",
    "        continue\n",
    "    syn = syns[0]\n",
    "    new_wd[word] = syn.lemma_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wss = []\n",
    "wordsinwss = []\n",
    "for word in word_dict:\n",
    "    for wordi in new_wd:\n",
    "        if word == wordi:\n",
    "            continue\n",
    "        stemmedX= [ hi_stem(x)  for x in word_dict(word) ]\n",
    "        stemmedY = [ hi_stem(x)  for x in new_wd(wordi) ]\n",
    "        wordNetMatch = [x for x in stemmedX for y in stemmedY if x == y ]\n",
    "        if wordNetMatch:\n",
    "            wss.append(wordNetMatch)\n",
    "            wordsinwss.append((word,wordi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['हत्या', 'खून', 'ख़ून', 'कत्ल', 'क़त्ल', 'वध', 'मारण', 'मारन', 'उज्जासन', 'प्रमथन', 'हनन', 'घात', 'मर्डर', 'अपघात', 'विघात', 'जबह', 'संघात', 'सङ्घात', 'प्रहण', 'संग्रहण', 'सङ्ग्रहण', 'प्रमाथ', 'शामनी', 'अवघात', 'क्राथ', 'विशसन', 'आर', 'आलंभ', 'आलम्भ', 'आलंभन', 'आलम्भन', 'निजुर', 'आहनन']\n",
      "['हत्या', 'खून', 'ख़ून', 'कत्ल', 'क़त्ल', 'वध', 'मर्डर', 'कटा']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suffixes = {\n",
    "    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n",
    "    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\"],\n",
    "    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\"],\n",
    "    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\"],\n",
    "    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\"],\n",
    "}\n",
    "\n",
    "def hi_stem(word):\n",
    "    for L in 5, 4, 3, 2, 1:\n",
    "        if len(word) > L + 1:\n",
    "            for suf in suffixes[L]:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-L]\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मार'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_stem(\"मारना\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are not considering all possible senses of the word. We are considering the first possible sense of the word, and corresponding to that we are considering all possible states "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl2",
   "language": "python",
   "name": "cl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
