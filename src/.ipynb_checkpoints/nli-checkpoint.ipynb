{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import tnt\n",
    "\n",
    "from nltk.corpus import indian\n",
    "\n",
    "train_data = indian.tagged_sents('hindi.pos')\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring NLTK\n",
    "\n",
    "Importing and configuring the nltk corpus and functions for Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiwn import pyiwn\n",
    "iwn = pyiwn.IndoWordNet('hindi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyiwn\n",
    "Pyiwn is a Python library which does wordnet lookups. It uses the CFTIB Worndet for Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postagWord(data):\n",
    "    \"\"\" A function to POS Tag a sentence\"\"\"\n",
    "    tagged_words = (tnt_pos_tagger.tag(word_tokenize(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_words(data):\n",
    "    \"\"\"A function to break the words into a string and remove the sentence ender\"\"\"\n",
    "    tokenized_words = word_tokenize(data)\n",
    "    final_words = []\n",
    "    for word in tokenized_words:\n",
    "        word = word.replace('।',\"\")\n",
    "        final_words.append(word)\n",
    "    return final_words\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suffixes = {\n",
    "    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n",
    "    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\"],\n",
    "    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\"],\n",
    "    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\"],\n",
    "    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\"],\n",
    "}\n",
    "\n",
    "def hi_stem(word):\n",
    "    for L in 5, 4, 3, 2, 1:\n",
    "        if len(word) > L + 1:\n",
    "            for suf in suffixes[L]:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-L]\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('stopwords.txt')\n",
    "stopwords = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "Stop words are function words and do not contribute to meaning of the sentence. Thus inorder to deal with the actual content that matters, stopwords are removed from the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getWordLemmaDict(sentence):\n",
    "    wd = {}\n",
    "    words = list_of_words(sentence)\n",
    "    words = map(hi_stem,words)\n",
    "    for word in words:\n",
    "        print(word)\n",
    "        syns = iwn.synsets(word)\n",
    "        print(syns)\n",
    "        if syns == []:\n",
    "            continue\n",
    "        syn = syns[0]\n",
    "        wd[word] = syn.lemma_names()\n",
    "    return wd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordNetCompare(word1,word2,word_dict1,word_dict2):    \n",
    "            stemmedX= [ hi_stem(x)  for x in word_dict1[word1] ]\n",
    "            stemmedY = [ hi_stem(x)  for x in word_dict2[word2] ]\n",
    "            wordNetMatch = [x for x in stemmedX for y in stemmedY if x == y ]\n",
    "            if wordNetMatch:\n",
    "              return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मार'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_stem(\"मारना\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are not considering all possible senses of the word. We are considering the first possible sense of the word, and corresponding to that we are considering all possible states \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CITE\n",
    "+ Cite the urdu parser\n",
    "+ IITB \n",
    "+ Pyiwin\n",
    "+ Lexical Injections for axiomatic theorem proving\n",
    "+ XNLI dataset \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = open(\"./../DataSet/s1_dp.txt\").read()\n",
    "s2 = open(\"./../DataSet/s2_dp.txt\").read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s1.split(\"Sentence:\")\n",
    "s2 = s2.split(\"Sentence:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependDictSent1 = []\n",
    "dependDictSent2 = []\n",
    "\n",
    "for i in s1:\n",
    "    wordDictParser= {}\n",
    "    x = i.split(\"\\n\")\n",
    "    for j in x:\n",
    "        y = j.split(\"\\t\")\n",
    "        try:\n",
    "            wordDictParser[y[1]] = y[7]\n",
    "        except:\n",
    "            continue\n",
    "    dependDictSent1.append(wordDictParser)\n",
    "for i in s2:\n",
    "    wordDictParser= {}\n",
    "    x = i.split(\"\\n\")\n",
    "    for j in x:\n",
    "        y = j.split(\"\\t\")\n",
    "        try:\n",
    "            wordDictParser[y[1]] = y[7]\n",
    "        except:\n",
    "            continue\n",
    "    dependDictSent2.append(wordDictParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"./../DataSet/s1.txt\").read()\n",
    "sent1 = f.split('\\n')\n",
    "f= open(\"./../DataSet/s2.txt\").read()\n",
    "sent2 = f.split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1,2):\n",
    "    s1 = sent1[i]\n",
    "    s2 = sent2[i]\n",
    "    val = True\n",
    "    orgVal = val\n",
    "    wordDict1 = getWordLemmaDict(s1)\n",
    "    wordDict2 = getWordLemmaDict(s2)\n",
    "    print(\"Her\")\n",
    "    for word1 in s1:\n",
    "        for word2 in s2:\n",
    "            if word1 == \"|\" or word2 == \"|\":\n",
    "                continue\n",
    "            if dependDictSent1[i][word1] == dependDictSent2[1][j]:\n",
    "                val = val\n",
    "            else:\n",
    "                if wordNetCompare(word1,word2,wordDict1,wordDict2):\n",
    "                    val = val\n",
    "                else:\n",
    "                    val = False\n",
    "                    break\n",
    "    if val == orgVal:\n",
    "        results.append(True)\n",
    "    else:\n",
    "        results.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हालांक\n",
      "[]\n",
      "मैं\n",
      "[]\n",
      "इसक\n",
      "[Synset('प्रेम.noun.120'), Synset('प्रेम.noun.19761')]\n",
      "बार\n",
      "[Synset('मदिरालय.noun.3915'), Synset('बार.noun.10791')]\n",
      "में\n",
      "[Synset('में में.noun.23048')]\n",
      "सोच\n",
      "[Synset('चिंता.noun.2131'), Synset('दृष्टिकोण.noun.3232')]\n",
      "भी\n",
      "[Synset('भी.adverb.28094'), Synset('भी.adverb.28181')]\n",
      "नह\n",
      "[Synset('नाखून.noun.4124')]\n",
      "रह\n",
      "[]\n",
      "था\n",
      "[]\n",
      "लेकिन\n",
      "[]\n",
      "मैं\n",
      "[]\n",
      "इत\n",
      "[Synset('इधर.adverb.1730'), Synset('यहाँ.adverb.2647')]\n",
      "परेशान\n",
      "[Synset('परेशान.adjective.5894')]\n",
      "था\n",
      "[]\n",
      "कि\n",
      "[]\n",
      "मुझ\n",
      "[]\n",
      "वापस\n",
      "[Synset('दुबारा.adverb.2814'), Synset('वापस.adverb.10819')]\n",
      "उसस\n",
      "[]\n",
      "बात\n",
      "[Synset('उक्ति.noun.1585'), Synset('घटना.noun.2968'), Synset('बातचीत.noun.3566'), Synset('उपदेश.noun.3812'), Synset('सीख.noun.3836'), Synset('विशिष्टता.noun.5677'), Synset('बहाना.noun.7201'), Synset('रहस्य.noun.7455'), Synset('बात.noun.21104'), Synset('जिक्र.noun.24314'), Synset('बात.noun.34256'), Synset('बात.noun.34477'), Synset('बात.noun.34478')]\n",
      "कर\n",
      "[Synset('हाथ.noun.491'), Synset('सूँड़.noun.3529'), Synset('कर.noun.4107'), Synset('हाथ.noun.13314'), Synset('हाथ.noun.13322')]\n",
      "ही\n",
      "[Synset('हृदय.noun.2886')]\n",
      "पड़\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'इत': ['इधर', 'इस ओर', 'यहाँ पर', 'इतः', 'इत', 'इतै', 'इत्थे'],\n",
       " 'इसक': ['प्रेम',\n",
       "  'प्यार',\n",
       "  'मुहब्बत',\n",
       "  'इश्क़',\n",
       "  'इश्क',\n",
       "  'प्रीति',\n",
       "  'प्रीत',\n",
       "  'अनुराग',\n",
       "  'छोह',\n",
       "  'लगन',\n",
       "  'अनुरंजन',\n",
       "  'अनुरञ्जन',\n",
       "  'राग',\n",
       "  'उलफत',\n",
       "  'उलफ़त',\n",
       "  'उल्फत',\n",
       "  'उल्फ़त',\n",
       "  'चाव',\n",
       "  'अभिप्रणय',\n",
       "  'प्रणव',\n",
       "  'पनव',\n",
       "  'उपधान',\n",
       "  'इखलास',\n",
       "  'शफक',\n",
       "  'शफ़क़',\n",
       "  'शफकत',\n",
       "  'शफ़क़त',\n",
       "  'अवन',\n",
       "  'अविद्वेष',\n",
       "  'इसक'],\n",
       " 'कर': ['हाथ',\n",
       "  'बाज़ू',\n",
       "  'हस्त',\n",
       "  'बाँह',\n",
       "  'बाहु',\n",
       "  'बाजू',\n",
       "  'भुजा',\n",
       "  'कर',\n",
       "  'अरत्नि',\n",
       "  'आच',\n",
       "  'शबर',\n",
       "  'सारंग'],\n",
       " 'नह': ['नाखून', 'नख', 'नह', 'नहँ', 'करवाल', 'करकंटक', 'करकण्टक', 'पुनर्णव'],\n",
       " 'परेशान': ['परेशान',\n",
       "  'तंग',\n",
       "  'उद्विग्न',\n",
       "  'बेचैन',\n",
       "  'व्यग्र',\n",
       "  'हैरान',\n",
       "  'हलकान',\n",
       "  'हिरासाँ',\n",
       "  'आजिज़',\n",
       "  'आजिज',\n",
       "  'आकुल'],\n",
       " 'बात': ['उक्ति',\n",
       "  'बोल',\n",
       "  'उद्गार',\n",
       "  'कथन',\n",
       "  'वचन',\n",
       "  'बात',\n",
       "  'बतिया',\n",
       "  'कहा',\n",
       "  'वाद',\n",
       "  'कलाम',\n",
       "  'अभिलाप',\n",
       "  'अभिहिति',\n",
       "  'आख्याति',\n",
       "  'गदि',\n",
       "  'उकत',\n",
       "  'उकति',\n",
       "  'उकुति',\n",
       "  'उगत',\n",
       "  'उगार',\n",
       "  'उग्गार'],\n",
       " 'बार': ['मदिरालय',\n",
       "  'मधुशाला',\n",
       "  'मद्यशाला',\n",
       "  'शराब घर',\n",
       "  'शराबघर',\n",
       "  'मयख़ाना',\n",
       "  'शराबख़ाना',\n",
       "  'पानागार',\n",
       "  'शराबखाना',\n",
       "  'मयखाना',\n",
       "  'सुरागार',\n",
       "  'बार',\n",
       "  'आपान'],\n",
       " 'भी': ['भी'],\n",
       " 'में': ['में में', 'मेंमें', 'में-में', 'में'],\n",
       " 'वापस': ['दुबारा',\n",
       "  'दोबारा',\n",
       "  'फिर',\n",
       "  'फिर से',\n",
       "  'पुनः',\n",
       "  'एक बार फिर',\n",
       "  'वापस',\n",
       "  'वापस से',\n",
       "  'एक बार और',\n",
       "  'वन्स मोर'],\n",
       " 'सोच': ['चिंता',\n",
       "  'चिन्ता',\n",
       "  'फ़िक्र',\n",
       "  'फिक्र',\n",
       "  'फिकर',\n",
       "  'परवाह',\n",
       "  'सोच',\n",
       "  'धुन',\n",
       "  'फिराक',\n",
       "  'फ़िराक़',\n",
       "  'आध्या',\n",
       "  'धौजन',\n",
       "  'अवसेर',\n",
       "  'अंदेशा',\n",
       "  'अन्देशा'],\n",
       " 'ही': ['हृदय',\n",
       "  'कलेजा',\n",
       "  'करेजा',\n",
       "  'दिल',\n",
       "  'हिय',\n",
       "  'जिगर',\n",
       "  'उर',\n",
       "  'मर्म स्थल',\n",
       "  'मर्म',\n",
       "  'जिया',\n",
       "  'जियरा',\n",
       "  'ही',\n",
       "  'उछंग',\n",
       "  'अवछंग',\n",
       "  'असह',\n",
       "  'उअर',\n",
       "  'हार्ट']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl2",
   "language": "python",
   "name": "cl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
