{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import tnt\n",
    "\n",
    "from nltk.corpus import indian\n",
    "\n",
    "train_data = indian.tagged_sents('hindi.pos')\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['हालांकि', 'मैं', 'इसके', 'बारे', 'में', 'सोच', 'भी', 'नहीं', 'रहा', 'था', 'लेकिन', 'मैं', 'इतना', 'परेशान', 'था', 'कि', 'मुझे', 'वापस', 'उससे', 'बात', 'करनी', 'ही', 'पड़ेगी']\n"
     ]
    }
   ],
   "source": [
    "data = \"हालांकि मैं इसके बारे में सोच भी नहीं रहा था लेकिन मैं इतना परेशान था कि मुझे वापस उससे बात करनी ही पड़ेगी\"\n",
    "data = data.replace('।',\"\")\n",
    "    \n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiwn import pyiwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('राम', 'Unk'), ('ने', 'PREP'), ('श्याम', 'Unk'), ('को', 'PREP'), ('मार', 'VFM'), ('डाला', 'VAUX')]\n"
     ]
    }
   ],
   "source": [
    "tagged_words = (tnt_pos_tagger.tag(word_tokenize(data)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwn = pyiwn.IndoWordNet('hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyiwn.pyiwn.IndoWordNet at 0x7f7d26d544e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = word_tokenize(data)\n",
    "f = open('stopwords.txt')\n",
    "stopwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['हालांकि', 'मैं', 'इसके', 'बारे', 'में', 'सोच', 'भी', 'नहीं', 'रहा', 'था', 'लेकिन', 'मैं', 'इतना', 'परेशान', 'था', 'कि', 'मुझे', 'वापस', 'उससे', 'बात', 'करनी', 'ही', 'पड़ेगी']\n"
     ]
    }
   ],
   "source": [
    "final_words = []\n",
    "for word in tokenized_words:\n",
    "    word = word.replace('।',\"\")\n",
    "    final_words.append(word)\n",
    "\n",
    "        \n",
    "print(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: हालांक\n",
      "Word: मैं\n",
      "Word: इसक\n",
      "Word: बार\n",
      "Word: में\n",
      "Word: सोच\n",
      "Word: भी\n",
      "Word: नह\n",
      "Word: रह\n",
      "Word: था\n",
      "Word: लेकिन\n",
      "Word: मैं\n",
      "Word: इत\n",
      "Word: परेशान\n",
      "Word: था\n",
      "Word: कि\n",
      "Word: मुझ\n",
      "Word: वापस\n",
      "Word: उसस\n",
      "Word: बात\n",
      "Word: कर\n",
      "Word: ही\n",
      "Word: पड़\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "final_words = map(hi_stem,final_words)\n",
    "for word in final_words:\n",
    "    syns = iwn.synsets(word)\n",
    "    \n",
    "    print(\"Word:\", word)\n",
    "    if syns == []:\n",
    "        continue\n",
    "\n",
    "#         syn = syns[0]\n",
    "#         print(syn.lemmas())\n",
    "#         print(\"Gloss:\",syn.gloss())\n",
    "#         print(\"Examples\")\n",
    "#         print(syn.examples())\n",
    "    syn = syns[0]\n",
    "    word_dict[word] = syn.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मैंने', 'उससे', 'दोबारा', 'बात', 'नहीं', 'की', 'है']\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"मैंने उससे दोबारा बात नहीं की है\"\n",
    "tokenized_words = word_tokenize(new_sentence)\n",
    "tokenized_word = map(hi_stem,tokenized_words)\n",
    "print(tokenized_words)\n",
    "new_wd = {}\n",
    "for word in tokenized_words:\n",
    "    syns = iwn.synsets(word)\n",
    "    if syns == []:\n",
    "        continue\n",
    "    syn = syns[0]\n",
    "    new_wd[word] = syn.lemma_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भी की\n",
      "[]\n",
      "भी दोबारा\n",
      "[]\n",
      "भी नहीं\n",
      "[]\n",
      "भी बात\n",
      "[]\n",
      "बार की\n",
      "[]\n",
      "बार दोबारा\n",
      "[]\n",
      "बार नहीं\n",
      "[]\n",
      "बार बात\n",
      "[]\n",
      "परेशान की\n",
      "[]\n",
      "परेशान दोबारा\n",
      "[]\n",
      "परेशान नहीं\n",
      "[]\n",
      "परेशान बात\n",
      "[]\n",
      "इत की\n",
      "[]\n",
      "इत दोबारा\n",
      "[]\n",
      "इत नहीं\n",
      "[]\n",
      "इत बात\n",
      "[]\n",
      "सोच की\n",
      "[]\n",
      "सोच दोबारा\n",
      "[]\n",
      "सोच नहीं\n",
      "[]\n",
      "सोच बात\n",
      "[]\n",
      "में की\n",
      "[]\n",
      "में दोबारा\n",
      "[]\n",
      "में नहीं\n",
      "[]\n",
      "में बात\n",
      "[]\n",
      "नह की\n",
      "[]\n",
      "नह दोबारा\n",
      "[]\n",
      "नह नहीं\n",
      "['नह']\n",
      "नह बात\n",
      "[]\n",
      "बात की\n",
      "[]\n",
      "बात दोबारा\n",
      "[]\n",
      "बात नहीं\n",
      "[]\n",
      "बात\n",
      "----\n",
      "ही की\n",
      "[]\n",
      "ही दोबारा\n",
      "[]\n",
      "ही नहीं\n",
      "[]\n",
      "ही बात\n",
      "[]\n",
      "इसक की\n",
      "[]\n",
      "इसक दोबारा\n",
      "[]\n",
      "इसक नहीं\n",
      "[]\n",
      "इसक बात\n",
      "[]\n",
      "वापस की\n",
      "[]\n",
      "वापस दोबारा\n",
      "['दुबार', 'दोबार', 'फिर', 'फिर स', 'पुनः', 'एक बार फिर', 'वापस', 'वापस स', 'एक बार और', 'वन्स मोर']\n",
      "वापस नहीं\n",
      "[]\n",
      "वापस बात\n",
      "[]\n",
      "कर की\n",
      "[]\n",
      "कर दोबारा\n",
      "[]\n",
      "कर नहीं\n",
      "[]\n",
      "कर बात\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "wss = []\n",
    "wordsinwss = []\n",
    "for word in word_dict:\n",
    "    for wordi in new_wd:\n",
    "        if word == wordi:\n",
    "            print(word)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        print(word,wordi)\n",
    "        stemmedX= [ hi_stem(x)  for x in word_dict[word] ]\n",
    "        stemmedY = [ hi_stem(x)  for x in new_wd[wordi] ]\n",
    "        wordNetMatch = [x for x in stemmedX for y in stemmedY if x == y ]\n",
    "        print(wordNetMatch)\n",
    "        if wordNetMatch:\n",
    "            wss.append(wordNetMatch)\n",
    "            wordsinwss.append((word,wordi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "किसी मनुष्य, प्राणी आदि को जान-बूझकर किसी उद्देश्य से मार डालने की क्रिया\n"
     ]
    }
   ],
   "source": [
    "word = \"मारन\"\n",
    "\n",
    "syns = iwn.synsets(word)\n",
    "syn = syns[0]\n",
    "print(syn.gloss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मार', 'आघात', 'पिटाई', 'ताड़न', 'धुलाई', 'धुनाई', 'ताड़ना', 'कुटंत', 'पिटंत', 'मरम्मत', 'प्रहारी', 'प्रताड़ना', 'प्रताड़न', 'अभ्याघात', 'थपेड़ा']\n"
     ]
    }
   ],
   "source": [
    "word = \"मार\"\n",
    "syns = iwn.synsets(word)\n",
    "syn = syns[0]\n",
    "print(syn.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suffixes = {\n",
    "    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n",
    "    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\"],\n",
    "    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\"],\n",
    "    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\"],\n",
    "    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\"],\n",
    "}\n",
    "\n",
    "def hi_stem(word):\n",
    "    for L in 5, 4, 3, 2, 1:\n",
    "        if len(word) > L + 1:\n",
    "            for suf in suffixes[L]:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-L]\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मार'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_stem(\"मारना\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are not considering all possible senses of the word. We are considering the first possible sense of the word, and corresponding to that we are considering all possible states \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CITE\n",
    "+ Cite the urdu parser\n",
    "+ IITB \n",
    "+ Pyiwin\n",
    "+ Lexical Injections for axiomatic theorem proving\n",
    "+ XNLI dataset \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl2",
   "language": "python",
   "name": "cl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
